{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "48d5f3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bc3ddc4",
   "metadata": {},
   "source": [
    "# Python Assignment - Question 1\n",
    "## Assumptions made:\n",
    "Data in excel A and excel b are identical, so made an assumption that same order ids can exist in different excels, else while removing duplicates one excel would completely get removed.\n",
    "\n",
    "Business Rules:\n",
    "1. Combine the data from both regions into a single table. \n",
    "2. Add a column total_sales which is calculated as QuantityOrdered * ItemPrice.\n",
    "3. Add a column region to identify the region of the sales record (A or B).\n",
    "4. Ensure that there are no duplicate entries based on OrderId.\n",
    "5. Add a new column net_sale, calculated as total_sales - PromotionDiscount.\n",
    "6. Exclude orders where the total sales amount is negative or zero after applying discounts.\n",
    "7. Load the transformed data into a the database of your choice.\n",
    "\n",
    "First the business rules transformations are applied on both excels separately and then both regions are combined into a single table as per business rule 1. Duplicate orderIds are removed from each excel separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a551c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd40502",
   "metadata": {},
   "source": [
    "### TASK1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ecc10152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract data from CSV\n",
    "def extract_data(file_path):\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "df = extract_data(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aad8870",
   "metadata": {},
   "source": [
    "### TASK2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "006363be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df, region):\n",
    "    \n",
    "    df = df.copy()\n",
    "#   Calculating the total sales amount\n",
    "    df['total_sales'] = df['QuantityOrdered'] * df['ItemPrice']\n",
    "    \n",
    "#   Adding a column to identify the region\n",
    "    df['region'] = region\n",
    "    \n",
    "#   Ensure unique entries based on OrderId\n",
    "    df = df.drop_duplicates(subset=[\"OrderId\"]).copy()\n",
    "    \n",
    "#   Function for extracting the discount value from Promotion discount    \n",
    "    def extract_discount(value):\n",
    "        try:\n",
    "            if pd.isna(value) or value == \"\":  \n",
    "                return 0.0\n",
    "            discount_dict = json.loads(value)  \n",
    "            return float(discount_dict.get(\"Amount\", 0)) \n",
    "        except (json.JSONDecodeError, TypeError, ValueError):\n",
    "            return 0.0 \n",
    "\n",
    "#   Extracting promotion discount and calculating net_sale        \n",
    "    df.loc[:, \"PromotionDiscount\"] = df[\"PromotionDiscount\"].apply(extract_discount)\n",
    "    \n",
    "    df.loc[:, \"net_sale\"] = df[\"total_sales\"] - df[\"PromotionDiscount\"]\n",
    "    \n",
    "#   Excluding the orders whose total sales amount is negative or zero    \n",
    "    df = df[df[\"total_sales\"] > 0].copy()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071d4485",
   "metadata": {},
   "source": [
    "### TASK3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3ab3d95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load the data to the db\n",
    "\n",
    "def load_data_to_db(df, db_name='sales_data.db'):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    df.to_sql('sales_data', conn, if_exists='replace', index=False)\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f6f46995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def etl_process():\n",
    "    # Extracting data from csv\n",
    "    df_a = extract_data('C:/Users/ajaya/Documents/order_region_a(in).csv')\n",
    "    df_b = extract_data('C:/Users/ajaya/Documents/order_region_b(in).csv')\n",
    "    \n",
    "    # Transforming the data\n",
    "    df_a = transform_data(df_a, 'A')\n",
    "    df_b = transform_data(df_b, 'B')\n",
    "    \n",
    "    # Combining  data\n",
    "    df_comb = pd.concat([df_a, df_b], ignore_index=True)\n",
    "    \n",
    "#     record_count = df_comb.shape[0]\n",
    "#     print(\"Number of records:\", record_count)\n",
    "    \n",
    "    #Load\n",
    "    load_data_to_db(df_comb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "51ad2288",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records: 41107\n",
      "Number of records: 41107\n",
      "Number of records: 82104\n"
     ]
    }
   ],
   "source": [
    "etl_process()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d57ba9",
   "metadata": {},
   "source": [
    "### TASK4 - Python functions to validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "11d8cebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records: 82104\n",
      "\n",
      "Total Sales by Region:\n",
      "   region    total_sales\n",
      "0      A  34,158,411.02\n",
      "1      B  34,158,411.02\n",
      "\n",
      "Average Sales per Transaction: 832.0766593584049\n",
      "\n",
      "Duplicate Order IDs:\n",
      " Empty DataFrame\n",
      "Columns: [OrderId, count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Database connection\n",
    "DB_PATH = \"sales_data.db\"\n",
    "\n",
    "\"\"\" Count total records in the sales_data table \"\"\"\n",
    "def get_total_records():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    query = \"SELECT COUNT(*) FROM sales_data\"\n",
    "    total_records = pd.read_sql(query, conn).iloc[0, 0]\n",
    "    conn.close()\n",
    "    return total_records\n",
    "\n",
    "\n",
    "\"\"\" Get total sales amount by region \"\"\"\n",
    "def get_total_sales_by_region():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    query = \"SELECT region, SUM(net_sale) AS total_sales FROM sales_data GROUP BY region\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    df[\"total_sales\"] = df[\"total_sales\"].apply(lambda x: \"{:,.2f}\".format(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\" Get the average sales amount per transaction \"\"\"\n",
    "def get_avg_sales_per_transaction():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    query = \"SELECT AVG(net_sale) AS avg_sales FROM sales_data\"\n",
    "    avg_sales = pd.read_sql(query, conn).iloc[0, 0]\n",
    "    conn.close()\n",
    "    return avg_sales\n",
    "\n",
    "\n",
    "\"\"\" Check for duplicate OrderId values \"\"\"\n",
    "def check_duplicate_order_ids():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    query = \"SELECT OrderId, COUNT(*) AS count FROM sales_data GROUP BY region, OrderId HAVING COUNT(*) > 1\"\n",
    "    df_duplicates = pd.read_sql(query, conn)\n",
    "    conn.close()\n",
    "    return df_duplicates\n",
    "\n",
    "# Printing output\n",
    "print(\"Total Records:\", get_total_records())\n",
    "print(\"\\nTotal Sales by Region:\\n\",get_total_sales_by_region())\n",
    "print(\"\\nAverage Sales per Transaction:\", get_avg_sales_per_transaction())\n",
    "print(\"\\nDuplicate Order IDs:\\n\", check_duplicate_order_ids())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b4d490",
   "metadata": {},
   "source": [
    "### TASK4 SQL queries to validate data\n",
    "\n",
    "SELECT COUNT(*) AS total_records FROM sales_data;\n",
    "\n",
    "SELECT region, SUM(net_sale) AS total_sales\n",
    "FROM sales_data\n",
    "GROUP BY region;\n",
    "\n",
    "SELECT AVG(net_sale) AS avg_sales_per_transaction FROM sales_data;\n",
    "\n",
    "SELECT OrderId, COUNT(*) AS duplicate_count\n",
    "FROM sales_data\n",
    "GROUP BY region,OrderId\n",
    "HAVING COUNT(*) > 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff163154",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08054254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
